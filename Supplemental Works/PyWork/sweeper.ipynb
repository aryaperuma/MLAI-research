{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lecture 36.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO36oM9PWVblV7umnTnNrZ3"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Mk6efWuxPwk6"},"source":["import numpy as np\r\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zX_uBOD2QZvo","executionInfo":{"status":"ok","timestamp":1613335587496,"user_tz":300,"elapsed":423,"user":{"displayName":"ggoldsztein@yahoo.com","photoUrl":"","userId":"06354275666408843048"}}},"source":["def shuffle_examples(X,Y):\r\n","  p = np.random.permutation(len(X))\r\n","  return X[p],Y[p]\r\n","\r\n","def split_train_validation_test(X,Y,p_train,p_train_val):\r\n","  n = int(p_train*len(X))\r\n","  m = int(p_train_val*len(X))\r\n","  return X[:n],Y[:n],X[n:m],Y[n:m],X[m:],Y[m:]   \r\n","\r\n","def scale(X):\r\n","  mu = np.mean(X,axis=0)\r\n","  st = np.std(X,axis=0)\r\n","  return (X-mu)/st,mu,st  \r\n","\r\n","def sigmoid(x):\r\n","  return 1/(1+np.exp(-x))\r\n","\r\n","def relu(x):\r\n","  return np.maximum(0,x)  \r\n","\r\n","def softmax(X):\r\n","  return np.exp(X)/(np.sum(np.exp(X),axis=1).reshape(-1,1))   \r\n","\r\n","def sigmoid_p(x):\r\n","  return sigmoid(x)*(1-sigmoid(x))\r\n","\r\n","def relu_p(x):\r\n","  return 1*(x >= 0)    \r\n","\r\n","def error_msr(Y,Y_hat):\r\n","  return np.sum((Y_hat-Y)**2)/(2*len(Y))\r\n","\r\n","def error_cross_entropy(Y,Y_hat):\r\n","  return -np.sum(Y*np.log(Y_hat))/len(Y)\r\n","\r\n","def norm_W(W):\r\n","  n_W = 0\r\n","  for l in range(1,len(W)):\r\n","    n_W = n_W + np.sum(W[l]**2)\r\n","  return n_W    \r\n","\r\n","def error(Y,Y_hat,cat,W,reg,la):\r\n","  if cat:\r\n","    J = error_cross_entropy(Y,Y_hat)\r\n","  else:\r\n","    J = error_msr(Y,Y_hat)\r\n","  if reg:\r\n","    J = J + la*norm_W(W)/len(Y)\r\n","  return J      \r\n","\r\n","# y is a one dimensional array y_1d = [0,2,1,3,0,2] (the categories of the examples)\r\n","# y_hat is 2d\r\n","def accuracy(Y_hat,y_1d):\r\n","  y_hat_1d = np.argmax(Y_hat,axis=1)\r\n","  correct_predictions = np.sum(y_hat_1d == y_1d)\r\n","  predictions = len(y_1d)\r\n","  accuracy = correct_predictions/predictions\r\n","  return accuracy\r\n","  \r\n","def h(x,act):\r\n","  if act == 'sigmoid':\r\n","    return sigmoid(x)\r\n","  if act == 'relu':\r\n","    return relu(x)\r\n","  if act == 'identity':\r\n","    return x\r\n","  if act == 'tanh':\r\n","    return np.tanh(x)\r\n","  if act == 'softmax':\r\n","    return softmax(x)  \r\n","  return 'Problem' \r\n","\r\n","def h_p(x,act):\r\n","  if act == 'sigmoid':\r\n","    return sigmoid_p(x)\r\n","  if act == 'relu':\r\n","    return relu_p(x)\r\n","  if act == 'identity':\r\n","    return 1\r\n","  if act == 'tanh':\r\n","    return 1/(np.cosh(x))**2\r\n","  return 'Problem'  \r\n","\r\n","def As_Zs(X,W,b,act):\r\n","  A = [X]\r\n","  Z = [0]\r\n","  for l in range(1,len(b)):\r\n","    Z.append(np.matmul(A[-1],W[l])+b[l])\r\n","    A.append(h(Z[-1],act[l]))\r\n","  return A,Z \r\n","\r\n","def gradients(A,Z,act,W,Y):\r\n","  Y_hat = A[-1]\r\n","  l = len(W)-1\r\n","  DJ_DW = []\r\n","  DJ_Db = []\r\n","  DJ_DZ = (Y_hat - Y)/len(Y)\r\n","  while l > 1:\r\n","    DJ_DA = np.matmul(DJ_DZ,W[l].T)\r\n","    DJ_DW.insert(0,np.matmul(A[l-1].T,DJ_DZ)) \r\n","    DJ_Db.insert(0,np.sum(DJ_DZ,axis=0))\r\n","    DJ_DZ = DJ_DA*h_p(Z[l-1],act[l-1])\r\n","    l = l-1\r\n","  DJ_DA = np.matmul(DJ_DZ,W[1].T)\r\n","  DJ_DW.insert(0,np.matmul(A[0].T,DJ_DZ)) \r\n","  DJ_Db.insert(0,np.sum(DJ_DZ,axis=0)) \r\n","  DJ_DW.insert(0,0) \r\n","  DJ_Db.insert(0,0)  \r\n","  return DJ_DW,DJ_Db  \r\n","\r\n","def update_parameters(W,b,DJ_DW,DJ_Db,c,reg,la,m):\r\n","  for l in range(1,len(b)):\r\n","    W[l] = W[l] - c*DJ_DW[l]\r\n","    b[l] = b[l] - c*DJ_Db[l]\r\n","  if reg:  \r\n","    for l in range(1,len(b)):\r\n","      W[l] = W[l] - 2*c*la*W[l]/m\r\n","  return W, b  \r\n","\r\n","def initialize_W_and_b(n):\r\n","  W = [0]\r\n","  b = [0]\r\n","  for l in range(1,len(n)):\r\n","    W.append(np.random.randn(n[l-1],n[l])/np.sqrt(n[l-1]))\r\n","    b.append(np.zeros(n[l]))\r\n","  return W, b \r\n","\r\n","def steepest(n,act,X,Y,epochs,c,cat,reg,la):\r\n","  W, b = initialize_W_and_b(n)\r\n","  J_list = []\r\n","  for i in range(epochs):\r\n","    A, Z = As_Zs(X,W,b,act)\r\n","    Y_hat = A[-1]\r\n","    J_list.append(error(Y,Y_hat,cat,W,reg,la))\r\n","    DJ_DW, DJ_Db = gradients(A,Z,act,W,y)\r\n","    W, b = update_parameters(W,b,DJ_DW,DJ_Db,c,reg,la,len(Y))\r\n","  return W, b, J_list   \r\n","\r\n","def predict(X,W,b,act):\r\n","  A,Z = As_Zs(X,W,b,act)\r\n","  return A[-1]\r\n","\r\n","def scale_predict(X,X_train_mean,X_train_std,W,b,act):\r\n","  return predict((X-X_train_mean)/X_train_std,W,b,act)\r\n","\r\n","def labels_1d_2d(y,n_c):\r\n","  return 1*(np.arange(n_c).reshape(1,n_c) == y.reshape(len(y),1))   "],"execution_count":2,"outputs":[]}]}